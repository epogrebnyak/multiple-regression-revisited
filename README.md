Качество оценок линейной регрессии 
==================================

При изучении линейной регрессии важно понимать связь между 
выполнением условий модели и статистическим качеством 
получаемых оценок для параметров регрессии. 

Как правило, все силы студентов уходят на изучение самих способов 
построения оценок параметров регрессии, а уж несмещенные ли они 
и состоятельные - *"ну, как получится, нам бы хоть какие-нибудь оценки посчитать"*. 
Отчасти это связано с тем, что в учебниках, как правило, отсутствуют 
наглядные экспериментальные иллюстрации того, что представляют 
собой несмещенные, состоятельные и эффективные оценки.

Мы предлагаем продемонстрировать качество оценок параметров регрессии 
при помощи примеров, в которых выбраны закон (data generating process)
получения истинных значений зависимой переменной и закон, описывающий
случайные ошибки. На основе этих законов делаются выборки наблюдений,
по которым оцениваются параметры регрессии. Получив выборку
параметров, мы можем построить их распределения и сравнить 
их с исходными истинными значениями параметров. Этот поход позволяет 
наглядно иллюстрировать свойства несмещенности и эффективности оценок.  

Эти изучения наиболее важны для случаи оценивания, когда 
не выполняются какие-либо из предположений метода наименьших кадратов 
(линейность модели, полный ранг, экзогенность объясняющей переменной и 
iid остатков). В этих случаях для получения качественных оценок 
параметров регрессии требуются другие методы оценивания или 
переформулировка модели.

Алгоритм расчетов
------------------

1. определяем истинный процесс генерации данных - формулy `f(x)`, 
   по которой из `x` получается истинное значение `y`
2. определяем процесс генерации случаных ошибок `e`, в стандартном случае
   это нормальное  распределение 
3. задаем границы и способ определения объясняющих переменных 
  `x`  
4. генерируем выборку наблюдений размера N `y(i) = f(x(i)) + e`, 
  `i = 1, ... , N`
5. оцениваем параметры регрессии `y` от `х`
6. повторяем генерацию выборки данных и оценку параметров, чтобы получить 
   не разовое точеченое значение, а распределение параметров регрессии
7. строим гистограмму и распределение интересующего параметра регрессии
8. обсуждаем отличия между "истинным" значенеим параметра из п. 1
   и результатами его оценки в п. 7.  в связи с выбранными 
   характеристиками процесса генерации данных.


Обычный случай 
--------------

- Процесс генерации данных: `y = 15 + 0.5x`
- Процесс генерации ошибок: `N(0, 4)`
- Код: [ols.r](ols.r)

Ниже показаны выборка данных, по котрой строится регрессия и 
распределение параметра наклона линии, оцененного по методу 
наименьших квадратов.

![](ols_true_model.png)
![](ols_b1.png)


Гетероскедастичность
--------------------

![](https://i1.wp.com/itfeature.com/wp-content/uploads/2012/07/preview006.png)

- Процесс генерации y: ...
- Процесс генерации x: ...
- Процесс генерации ошибок: ...
- Код: [heteroscedasticity.r](heteroscedasticity.r)
- На основе: https://stats.stackexchange.com/questions/33028/measures-of-residuals-heteroscedasticity


Выводы:
- гетероскедастичность уменьшает эффеткивность, но сохраняет несмещенность
- эмпирическое распределение оценки нужно с чем-то сравнивать, 
  у нас нет заранее истинного абсолютного значения дисперсии оценки (или есть?
  знаем ли мы по распределению ошибки распределение параметра регрессии?)

![](hsc1.png)
![](hsc2.png)


Вопрос
------

Как получить хорошие иллюстрации неэффективности МНК-оценки
с гетероскедастичностью? Как, например, [в оценке числа "пи"][pi-sas]

[pi-sas]: https://blogs.sas.com/content/iml/2016/03/14/monte-carlo-estimates-of-pi.html

Что-то наподобие рисунков ниже:

[![](journal.pone.0110257.g002.png)](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0110257)


[![](https://blogs.sas.com/content/iml/files/2016/03/piMCest1.png)][pi-sas]

Комментариии
------------

**Объясняющая переменная**. Чтобы получить значения `y` по формуле 
процесса генерации данных нам нужны значения `x`. От того как распредлены 
`x` зависят свойства оценок по линейной регрессии, например, чем больше 
дисперсия `x`, тем ниже `R2`.
В стандартном случае `x` выбираются из равномерного распределения 
на отрезке `[0,100]`. Мы считаем такие `x` детерминированными
для целей построения выборки наблюдений.
