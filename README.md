Качество оценок линейной регрессии 
==================================

При изучении линейной регрессии важно понимать связь между 
выполнением условий модели и статистическим качеством 
получаемых оценок для параметров регрессии. 

Как правило, все силы студентов уходят на изучение самих способов 
построения оценок параметров регрессии, а уж несмещенные ли они 
и состоятельные - *"ну, как получится, нам бы хоть какие-нибудь оценки посчитать"*. 
Отчасти это связано с тем, что в учебниках, как правило, отсутствуют 
наглядные экспериментальные иллюстрации того, что представляют 
собой несмещенные, состоятельные и эффективные оценки.

Мы предлагаем продемонстрировать качество оценок параметров регрессии 
при помощи примеров, в которых выбраны закон (data generating process)
получения истинных значений зависимой переменной и закон, описывающий
случайные ошибки. На основе этих законов делаются выборки наблюдений,
по которым оцениваются параметры регрессии. Получив выборку
параметров, мы можем построить их распределения и сравнить 
их с исходными истинными значениями параметров. Этот поход позволяет 
наглядно иллюстрировать свойства несмещенности и эффективности оценок.  

Эти изучения наиболее важны для случаи оценивания, когда 
не выполняются какие-либо из предположений метода наименьших кадратов 
(линейность модели, полный ранг, экзогенность объясняющей переменной и 
iid остатков). В этих случаях для получения качественных оценок 
параметров регрессии требуются другие методы оценивания или 
переформулировка модели.

Алгоритм расчетов
------------------

1. определяем истинный процесс генерации данных - формулy `f(x)`, 
   по которой из `x` получается истинное значение `y`
2. определяем процесс генерации случаных ошибок `e`, в стандартном случае
   это нормальное  распределение 
3. задаем границы и способ определения объясняющих переменных 
  `x`  
4. генерируем выборку наблюдений размера N `y(i) = f(x(i)) + e`, 
  `i = 1, ... , N`
5. оцениваем параметры регрессии `y` от `х`
6. повторяем генерацию выборки данных и оценку параметров, чтобы получить 
   не разовое точеченое значение, а распределение параметров регрессии
7. строим гистограмму и распределение интересующего параметра регрессии
8. обсуждаем отличия между "истинным" значенеим параметра из п. 1
   и результатами его оценки в п. 7.  в связи с выбранными 
   характеристиками процесса генерации данных.


Обычный случай 
--------------

- Процесс генерации данных: `y = 15 + 0.5x`
- Процесс генерации ошибок: `N(0, 4)`
- Код: [ols.r](ols.r)

Ниже показаны выборка данных, по котрой строится регрессия и 
распределение параметра наклона линии, оцененного по методу 
наименьших квадратов.

![](ols_true_model.png)
![](ols_b1.png)


Гетероскедастичность
--------------------

- Процесс генерации y: ...
- Процесс генерации x: ...
- Процесс генерации ошибок: ...
- Код: 
[heteroscedasticity.r](heteroscedasticity.r)


![](hsc1.png)
![](hsc2.png)


Вопрос
------

Как получить хорошие иллюстрации неэффективности МНК-оценки
с гетероскедастичностью? 


Комментариии
------------

**Объясняющая переменная**. Чтобы получить значения `y` по формуле 
процесса генерации данных нам нужны значения `x`. От того как распредлены 
`x` зависят свойства оценок по линейной регрессии, например, чем больше 
дисперсия `x`, тем ниже `R2`.
В стандартном случае `x` выбираются из равномерного распределения 
на отрезке `[0,100]`. Мы считаем такие `x` детерминированными
для целей построения выборки наблюдений.
